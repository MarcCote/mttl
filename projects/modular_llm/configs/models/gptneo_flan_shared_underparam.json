{
    "num_train_epochs": 1,
    "learning_rate": 0.0003,
    "micro_batch_size": 8,
    "train_batch_size": 32,
    "predict_batch_size": 1,
    "model": "EleutherAI/gpt-neo-1.3B",
    "model_family": "gpt",
    "optimizer": "adamw",
    "eval_every": 40,
    "warmup_proportion": 0.06,
    "precision": "bf16",
    "dataset": "sordonia/flan-10k-flat",
    "lora_rank": 4,
    "lora_dropout": 0.05,
    "weight_decay": 0.00,
    "n_skills": 1,
    "model_modifier": "lora",
    "modify_modules": ".*",
    "modify_layers": "k_proj|v_proj|q_proj|out_proj",
    "trainable_param_names": ".*lora_[ab].*",
    "pipeline_eval_tasks": "all",
    "remove_phi_eval_tasks": true
    
}