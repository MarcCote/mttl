{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/comp_3.9/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/anaconda/envs/comp_3.9/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering modifier...lora\n",
      "Registering modifier...poly\n",
      "Registering modifier...skilled\n",
      "Registering modifier...kv_adapter\n",
      "Registering modifier...poly_kv_adapter\n",
      "Registering modifier...prompt_tuning\n",
      "Registering modifier...poly_prompt_tuning\n",
      "Registering modifier...hard_prompt\n",
      "Registering multi-expert selector...poly_router\n",
      "Registering multi-expert selector...moe_rkhs_router\n",
      "Registering multi-expert selector...poly_router_dir\n",
      "Registering multi-expert selector...info_selector\n",
      "Registering multi-expert selector...task_selector\n",
      "Registering multi-expert selector...kv_task_selector\n",
      "Registering multi-expert selector...kv_concat_selector\n",
      "Registering multi-expert selector...kv_norm_selector\n",
      "Registering multi-expert selector...kv_concat_norm_selector\n",
      "Registering multi-expert selector...kv_task_norm_selector\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import torch\n",
    "import wandb\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from dataclasses import replace\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "from huggingface_hub import login\n",
    "from tempfile import TemporaryDirectory\n",
    "from pytorch_lightning import seed_everything\n",
    "from huggingface_hub import create_repo, login, HfApi\n",
    "\n",
    "from projects.wiki_experts.train_experts_main import get_datamodule\n",
    "from projects.wiki_experts.src.evolution.utils import (\n",
    "    get_loss,\n",
    "    init_wandb_logger,\n",
    "    TableLogger,\n",
    "    get_svd_embedding\n",
    ")\n",
    "\n",
    "from projects.wiki_experts.src.expert_trainer import ExpertTrainer\n",
    "from mttl.models.modifiers.expert_containers.expert_library import (\n",
    "    get_best_expert_for_task,\n",
    "    get_best_expert_for_score,\n",
    "    LocalExpertLibrary,\n",
    "    HFExpertLibrary,\n",
    "    ExpertLibrary,\n",
    "    Score,\n",
    ")\n",
    "from projects.wiki_experts.src.evolution.evaluators import (\n",
    "    Evaluator,\n",
    "    prepare_evaluator,\n",
    "    EvalCallback,\n",
    ")\n",
    "\n",
    "\n",
    "from mttl.models.modifiers.expert_containers.module_graph import Expert\n",
    "\n",
    "from projects.wiki_experts.src.evolution.config import (\n",
    "    EvolExpertConfig,\n",
    "    increase_version,\n",
    ")\n",
    "from projects.wiki_experts.src.evolution.nevergrad_opt import NGRoutingOptimizer\n",
    "from mttl.utils import setup_logging, logger\n",
    "from projects.wiki_experts.src.expert_model import MultiExpertModel\n",
    "from projects.wiki_experts.src.evolution.experiment_state import ExperimentState\n",
    "from mttl.vllm_engines.engines import free_memory\n",
    "from projects.wiki_experts.src.evolution.transfer_matrix import (\n",
    "    eval_all_experts_on_task,\n",
    "    eval_expert_on_task,\n",
    ")\n",
    "from mttl.datamodule.base import DefaultDataModule\n",
    "from mttl.models.modifiers.expert_containers.library_transforms import (\n",
    "    SVDEmbeddingTransform,\n",
    "    SVDEmbeddingTransformConfig,\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from huggingface_hub import login, HfApi, logout\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "from mttl.models.modifiers.expert_containers.module_graph import load_expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/v-oostapenko/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "hf_api_key = \"\"\n",
    "login(token=hf_api_key)\n",
    "user = HfApi(token=hf_api_key).whoami()\n",
    "os.environ[\"HF_TOKEN\"] = hf_api_key\n",
    "# hf_repo_id = \"sordonia/library-phi_2-v3\"\n",
    "hf_repo_id = \"sordonia/library-phi_2-v3-2epc\"\n",
    "# expert_lib =  HFExpertLibrary(hf_repo_id)\n",
    "local_lib_location = f\"/tmp/{hf_repo_id}\"\n",
    "os.makedirs(local_lib_location, exist_ok=True)\n",
    "# expert_lib:LocalExpertLibrary = LocalExpertLibrary.create_from_remote(expert_lib, local_lib_location)\n",
    "expert_lib:LocalExpertLibrary = LocalExpertLibrary(local_lib_location)\n",
    "\n",
    "experts_to_remove = [\"bool_q_1_0_0\", \"ai2_arc_ARC_Easy_1_0_0\", \"openbookqa_0_1_0\", \"ai2_arc_ARC_Challenge_1_0_0\", \"hellaswag_1_1_0\", \"piqa_1_0_0\", \"winogrande_1_1_0\"]\n",
    "for expert_name in experts_to_remove:\n",
    "    if expert_name in expert_lib:\n",
    "        expert_lib.remove_expert(expert_name)\n",
    "assert len(expert_lib) == 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_embeddings():\n",
    "    svd_embedder = SVDEmbeddingTransform(\n",
    "        SVDEmbeddingTransformConfig(sparsity_threshold=0.5)\n",
    "    )\n",
    "    svd_embedder.transform(expert_lib, upload_to_hf=True)\n",
    "    del svd_embedder\n",
    "\n",
    "\n",
    "# module to embedding\n",
    "module2embed = {}\n",
    "for n, m in expert_lib.items():\n",
    "    module2embed[n] = get_svd_embedding(expert_lib,n)\n",
    "    if module2embed[n] is None:\n",
    "        create_embeddings()\n",
    "        module2embed[n] = get_svd_embedding(expert_lib,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Extract the embeddings as a numpy array\n",
    "embeddings = np.array(list(module2embed.values()))\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(embeddings, embeddings)\n",
    "\n",
    "# Specify the number of clusters (K)\n",
    "K = 25  # Adjust this based on your requirements\n",
    "\n",
    "# Initialize KMeans with cosine similarity as the metric\n",
    "kmeans = KMeans(n_clusters=K, init='k-means++', n_init=10, random_state=42)\n",
    "\n",
    "# Fit the KMeans model\n",
    "kmeans.fit(cosine_sim_matrix)\n",
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding glue_sst2_2_0_0 belongs to Cluster 2\n",
      "Embedding dream_read_the_following_conversation_and_answer_the_question belongs to Cluster 21\n",
      "Embedding race_middle_Read_the_article_and_answer_the_question_no_option_ belongs to Cluster 8\n",
      "Embedding adversarial_qa_droberta_generate_question belongs to Cluster 23\n",
      "Embedding adversarial_qa_dbidaf_question_context_answer belongs to Cluster 19\n",
      "Embedding app_reviews_convert_to_star_rating belongs to Cluster 9\n",
      "Embedding race_high_Select_the_best_answer belongs to Cluster 8\n",
      "Embedding super_glue_rte_1_0_2 belongs to Cluster 24\n",
      "Embedding true_case belongs to Cluster 2\n",
      "Embedding wiqa_what_might_be_the_first_step_of_the_process belongs to Cluster 3\n",
      "Embedding quail_description_context_question_answer_id belongs to Cluster 8\n",
      "Embedding quail_context_question_description_text belongs to Cluster 8\n",
      "Embedding stream_qed belongs to Cluster 10\n",
      "Embedding huggingface_xsum belongs to Cluster 10\n",
      "Embedding cos_e_v1_11_question_option_description_text belongs to Cluster 6\n",
      "Embedding wiqa_what_is_the_final_step_of_the_following_process belongs to Cluster 3\n",
      "Embedding ropes_background_new_situation_answer belongs to Cluster 1\n",
      "Embedding wiki_qa_found_on_google belongs to Cluster 5\n",
      "Embedding cot_esnli belongs to Cluster 2\n",
      "Embedding social_i_qa_Show_choices_and_generate_answer belongs to Cluster 9\n",
      "Embedding cot_gsm8k belongs to Cluster 10\n",
      "Embedding app_reviews_categorize_rating_using_review belongs to Cluster 9\n",
      "Embedding cot_sensemaking belongs to Cluster 11\n",
      "Embedding trec_1_0_0 belongs to Cluster 2\n",
      "Embedding super_glue_wic_1_0_2 belongs to Cluster 24\n",
      "Embedding ropes_prompt_bottom_no_hint belongs to Cluster 1\n",
      "Embedding quartz_answer_question_based_on belongs to Cluster 15\n",
      "Embedding super_glue_record_1_0_2 belongs to Cluster 4\n",
      "Embedding yelp_polarity_reviews_0_2_0 belongs to Cluster 2\n",
      "Embedding race_middle_Is_this_the_right_answer belongs to Cluster 21\n",
      "Embedding quoref_Context_Contains_Answer belongs to Cluster 20\n",
      "Embedding cos_e_v1_11_rationale belongs to Cluster 0\n",
      "Embedding natural_questions_open_1_0_0 belongs to Cluster 7\n",
      "Embedding ropes_plain_background_situation belongs to Cluster 1\n",
      "Embedding web_questions_whats_the_answer belongs to Cluster 7\n",
      "Embedding race_high_Read_the_article_and_answer_the_question_no_option_ belongs to Cluster 8\n",
      "Embedding anli_r3_0_1_0 belongs to Cluster 24\n",
      "Embedding duorc_SelfRC_generate_question_by_answer belongs to Cluster 16\n",
      "Embedding quoref_Find_Answer belongs to Cluster 20\n",
      "Embedding duorc_ParaphraseRC_movie_director belongs to Cluster 20\n",
      "Embedding sciq_Direct_Question_Closed_Book_ belongs to Cluster 6\n",
      "Embedding qasc_qa_with_separated_facts_3 belongs to Cluster 6\n",
      "Embedding lambada_1_0_0 belongs to Cluster 12\n",
      "Embedding quartz_given_the_fact_answer_the_q belongs to Cluster 15\n",
      "Embedding super_glue_cb_1_0_2 belongs to Cluster 5\n",
      "Embedding quartz_answer_question_below belongs to Cluster 15\n",
      "Embedding duorc_ParaphraseRC_answer_question belongs to Cluster 16\n",
      "Embedding wmt16_translate_ro_en_1_0_0 belongs to Cluster 13\n",
      "Embedding dream_generate_last_utterance belongs to Cluster 12\n",
      "Embedding wiki_qa_Topic_Prediction_Answer_Only belongs to Cluster 5\n",
      "Embedding kilt_tasks_hotpotqa_final_exam belongs to Cluster 9\n",
      "Embedding glue_cola_2_0_0 belongs to Cluster 2\n",
      "Embedding race_high_Select_the_best_answer_no_instructions_ belongs to Cluster 8\n",
      "Embedding quail_context_description_question_answer_id belongs to Cluster 8\n",
      "Embedding ag_news_subset_1_0_0 belongs to Cluster 2\n",
      "Embedding paws_wiki_1_1_0 belongs to Cluster 24\n",
      "Embedding sciq_Multiple_Choice belongs to Cluster 6\n",
      "Embedding wiki_qa_Direct_Answer_to_Question belongs to Cluster 5\n",
      "Embedding gem_dart_1_1_0 belongs to Cluster 18\n",
      "Embedding cos_e_v1_11_generate_explanation_given_text belongs to Cluster 0\n",
      "Embedding wiki_hop_original_generate_object belongs to Cluster 14\n",
      "Embedding race_high_Taking_a_test belongs to Cluster 8\n",
      "Embedding wiqa_what_might_be_the_last_step_of_the_process belongs to Cluster 3\n",
      "Embedding wiki_bio_key_content belongs to Cluster 17\n",
      "Embedding quoref_Found_Context_Online belongs to Cluster 20\n",
      "Embedding super_glue_wsc_fixed_1_0_2 belongs to Cluster 5\n",
      "Embedding wiqa_does_the_supposed_perturbation_have_an_effect belongs to Cluster 9\n",
      "Embedding adversarial_qa_droberta_tell_what_it_is belongs to Cluster 19\n",
      "Embedding cos_e_v1_11_question_description_option_text belongs to Cluster 6\n",
      "Embedding gem_common_gen_1_1_0 belongs to Cluster 18\n",
      "Embedding quoref_Read_And_Extract_ belongs to Cluster 20\n",
      "Embedding cot_creak belongs to Cluster 11\n",
      "Embedding cot_gsm8k_ii belongs to Cluster 9\n",
      "Embedding duorc_ParaphraseRC_title_generation belongs to Cluster 16\n",
      "Embedding wiki_qa_Is_This_True_ belongs to Cluster 24\n",
      "Embedding math_dataset_algebra__linear_1d_1_0_0 belongs to Cluster 2\n",
      "Embedding unified_qa_science_inst belongs to Cluster 5\n",
      "Embedding quartz_use_info_from_question_paragraph belongs to Cluster 15\n",
      "Embedding web_questions_question_answer belongs to Cluster 7\n",
      "Embedding duorc_ParaphraseRC_decide_worth_it belongs to Cluster 16\n",
      "Embedding stream_aqua belongs to Cluster 11\n",
      "Embedding dbpedia_14_pick_one_category_for_the_following_text belongs to Cluster 23\n",
      "Embedding super_glue_multirc_1_0_2 belongs to Cluster 9\n",
      "Embedding dbpedia_14_given_a_choice_of_categories_ belongs to Cluster 23\n",
      "Embedding sciq_Direct_Question belongs to Cluster 6\n",
      "Embedding kilt_tasks_hotpotqa_combining_facts belongs to Cluster 7\n",
      "Embedding quoref_What_Is_The_Answer belongs to Cluster 20\n",
      "Embedding web_questions_short_general_knowledge_q belongs to Cluster 7\n",
      "Embedding qasc_qa_with_separated_facts_2 belongs to Cluster 6\n",
      "Embedding wiqa_which_of_the_following_is_the_supposed_perturbation belongs to Cluster 9\n",
      "Embedding cnn_dailymail_3_4_0 belongs to Cluster 12\n",
      "Embedding duorc_ParaphraseRC_generate_question belongs to Cluster 16\n",
      "Embedding race_middle_Select_the_best_answer belongs to Cluster 8\n",
      "Embedding kilt_tasks_hotpotqa_straighforward_qa belongs to Cluster 7\n",
      "Embedding duorc_SelfRC_build_story_around_qa belongs to Cluster 22\n",
      "Embedding adversarial_qa_dbidaf_generate_question belongs to Cluster 23\n",
      "Embedding snli_1_1_0 belongs to Cluster 11\n",
      "Embedding app_reviews_convert_to_rating belongs to Cluster 9\n",
      "Embedding wiki_hop_original_choose_best_object_affirmative_3 belongs to Cluster 14\n",
      "Embedding quail_context_question_description_answer_id belongs to Cluster 8\n",
      "Embedding cos_e_v1_11_i_think belongs to Cluster 0\n",
      "Embedding quoref_Guess_Title_For_Context belongs to Cluster 4\n",
      "Embedding quac_1_0_0 belongs to Cluster 4\n",
      "Embedding cos_e_v1_11_question_option_description_id belongs to Cluster 6\n",
      "Embedding quoref_Answer_Test belongs to Cluster 20\n",
      "Embedding wiki_hop_original_choose_best_object_interrogative_1 belongs to Cluster 14\n",
      "Embedding duorc_SelfRC_question_answering belongs to Cluster 16\n",
      "Embedding wiki_hop_original_explain_relation belongs to Cluster 14\n",
      "Embedding ropes_new_situation_background_answer belongs to Cluster 1\n",
      "Embedding dbpedia_14_given_list_what_category_does_the_paragraph_belong_to belongs to Cluster 23\n",
      "Embedding race_high_Is_this_the_right_answer belongs to Cluster 21\n",
      "Embedding quail_description_context_question_answer_text belongs to Cluster 8\n",
      "Embedding cot_strategyqa belongs to Cluster 5\n",
      "Embedding ropes_given_background_situation belongs to Cluster 1\n",
      "Embedding quail_context_question_answer_description_text belongs to Cluster 8\n",
      "Embedding cot_ecqa_ii belongs to Cluster 5\n",
      "Embedding ropes_prompt_bottom_hint_beginning belongs to Cluster 1\n",
      "Embedding gem_wiki_lingua_english_en_1_1_0 belongs to Cluster 10\n",
      "Embedding glue_qqp_2_0_0 belongs to Cluster 24\n",
      "Embedding fix_punct belongs to Cluster 2\n",
      "Embedding wiqa_effect_with_string_answer belongs to Cluster 9\n",
      "Embedding adversarial_qa_droberta_based_on belongs to Cluster 19\n",
      "Embedding imdb_reviews_plain_text_1_0_0 belongs to Cluster 2\n",
      "Embedding race_high_Select_the_best_answer_generate_span_ belongs to Cluster 8\n",
      "Embedding race_middle_Select_the_best_answer_generate_span_ belongs to Cluster 8\n",
      "Embedding race_middle_Write_a_multi_choice_question_for_the_following_article belongs to Cluster 12\n",
      "Embedding quarel_do_not_use belongs to Cluster 21\n",
      "Embedding duorc_SelfRC_title_generation belongs to Cluster 16\n",
      "Embedding qasc_qa_with_separated_facts_5 belongs to Cluster 6\n",
      "Embedding wiki_qa_exercise belongs to Cluster 5\n",
      "Embedding duorc_ParaphraseRC_generate_question_by_answer belongs to Cluster 16\n",
      "Embedding web_questions_get_the_answer belongs to Cluster 7\n",
      "Embedding wiki_hop_original_choose_best_object_affirmative_1 belongs to Cluster 14\n",
      "Embedding duorc_ParaphraseRC_extract_answer belongs to Cluster 16\n",
      "Embedding dream_baseline belongs to Cluster 21\n",
      "Embedding adversarial_qa_dbert_answer_the_following_q belongs to Cluster 19\n",
      "Embedding gigaword_1_2_0 belongs to Cluster 10\n",
      "Embedding ropes_prompt_beginning belongs to Cluster 1\n",
      "Embedding quail_context_question_answer_description_id belongs to Cluster 8\n",
      "Embedding duorc_SelfRC_answer_question belongs to Cluster 16\n",
      "Embedding kilt_tasks_hotpotqa_complex_question belongs to Cluster 9\n",
      "Embedding quartz_having_read_above_passage belongs to Cluster 6\n",
      "Embedding quail_context_description_question_answer_text belongs to Cluster 8\n",
      "Embedding cos_e_v1_11_question_description_option_id belongs to Cluster 6\n",
      "Embedding ropes_read_background_situation belongs to Cluster 1\n",
      "Embedding wiki_hop_original_choose_best_object_interrogative_2 belongs to Cluster 14\n",
      "Embedding dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to belongs to Cluster 23\n",
      "Embedding gem_web_nlg_en_1_1_0 belongs to Cluster 18\n",
      "Embedding adversarial_qa_droberta_question_context_answer belongs to Cluster 19\n",
      "Embedding qasc_qa_with_separated_facts_1 belongs to Cluster 6\n",
      "Embedding wiki_qa_automatic_system belongs to Cluster 9\n",
      "Embedding ropes_plain_bottom_hint belongs to Cluster 1\n",
      "Embedding duorc_SelfRC_decide_worth_it belongs to Cluster 16\n",
      "Embedding duorc_ParaphraseRC_question_answering belongs to Cluster 16\n",
      "Embedding cos_e_v1_11_explain_why_human belongs to Cluster 0\n",
      "Embedding word_segment belongs to Cluster 2\n",
      "Embedding cot_creak_ii belongs to Cluster 9\n",
      "Embedding anli_r2_0_1_0 belongs to Cluster 2\n",
      "Embedding cos_e_v1_11_description_question_option_text belongs to Cluster 6\n",
      "Embedding quarel_heres_a_story belongs to Cluster 21\n",
      "Embedding qasc_qa_with_combined_facts_1 belongs to Cluster 6\n",
      "Embedding app_reviews_generate_review belongs to Cluster 18\n",
      "Embedding wiki_bio_what_content belongs to Cluster 17\n",
      "Embedding race_high_Write_a_multi_choice_question_for_the_following_article belongs to Cluster 12\n",
      "Embedding qasc_is_correct_1 belongs to Cluster 24\n",
      "Embedding quoref_Answer_Question_Given_Context belongs to Cluster 20\n",
      "Embedding squad_v2_0_3_0_0 belongs to Cluster 4\n",
      "Embedding web_questions_potential_correct_answer belongs to Cluster 7\n",
      "Embedding trivia_qa_rc_1_1_0 belongs to Cluster 7\n",
      "Embedding wmt16_translate_de_en_1_0_0 belongs to Cluster 13\n",
      "Embedding cos_e_v1_11_description_question_option_id belongs to Cluster 6\n",
      "Embedding wiki_hop_original_generate_subject belongs to Cluster 14\n",
      "Embedding ropes_plain_no_background belongs to Cluster 1\n",
      "Embedding quarel_choose_between belongs to Cluster 21\n",
      "Embedding stream_qed_ii belongs to Cluster 5\n",
      "Embedding wiki_bio_guess_person belongs to Cluster 4\n",
      "Embedding anli_r1_0_1_0 belongs to Cluster 2\n",
      "Embedding quail_context_description_question_text belongs to Cluster 8\n",
      "Embedding cot_ecqa belongs to Cluster 0\n",
      "Embedding quail_context_question_description_answer_text belongs to Cluster 8\n",
      "Embedding wiki_bio_who belongs to Cluster 17\n",
      "Embedding wiki_qa_Topic_Prediction_Question_Only belongs to Cluster 5\n",
      "Embedding glue_stsb_2_0_0 belongs to Cluster 11\n",
      "Embedding cos_e_v1_11_aligned_with_common_sense belongs to Cluster 0\n",
      "Embedding aeslc_1_0_0 belongs to Cluster 10\n",
      "Embedding dream_generate_first_utterance belongs to Cluster 12\n",
      "Embedding wmt16_translate_fi_en_1_0_0 belongs to Cluster 13\n",
      "Embedding adversarial_qa_dbidaf_answer_the_following_q belongs to Cluster 19\n",
      "Embedding dream_answer_to_dialogue belongs to Cluster 12\n",
      "Embedding glue_qnli_2_0_0 belongs to Cluster 24\n",
      "Embedding adversarial_qa_droberta_answer_the_following_q belongs to Cluster 19\n",
      "Embedding cot_sensemaking_ii belongs to Cluster 9\n",
      "Embedding adversarial_qa_dbert_tell_what_it_is belongs to Cluster 19\n",
      "Embedding glue_mnli_2_0_0 belongs to Cluster 24\n",
      "Embedding quail_description_context_question_text belongs to Cluster 8\n",
      "Embedding super_glue_copa_1_0_2 belongs to Cluster 5\n",
      "Embedding social_i_qa_Check_if_a_random_answer_is_valid_or_not belongs to Cluster 9\n",
      "Embedding social_i_qa_Generate_the_question_from_the_answer belongs to Cluster 9\n",
      "Embedding social_i_qa_Show_choices_and_generate_index belongs to Cluster 21\n",
      "Embedding kilt_tasks_hotpotqa_formulate belongs to Cluster 7\n",
      "Embedding gem_e2e_nlg_1_1_0 belongs to Cluster 18\n",
      "Embedding para_crawl_enes belongs to Cluster 13\n",
      "Embedding duorc_SelfRC_extract_answer belongs to Cluster 16\n",
      "Embedding sciq_Multiple_Choice_Closed_Book_ belongs to Cluster 6\n",
      "Embedding race_high_Write_a_multi_choice_question_options_given_ belongs to Cluster 12\n",
      "Embedding race_middle_Taking_a_test belongs to Cluster 8\n",
      "Embedding social_i_qa_I_was_wondering belongs to Cluster 11\n",
      "Embedding adversarial_qa_dbert_generate_question belongs to Cluster 23\n",
      "Embedding quoref_Guess_Answer belongs to Cluster 20\n",
      "Embedding race_middle_Write_a_multi_choice_question_options_given_ belongs to Cluster 12\n",
      "Embedding quartz_use_info_from_paragraph_question belongs to Cluster 15\n",
      "Embedding quoref_Answer_Friend_Question belongs to Cluster 20\n",
      "Embedding qasc_is_correct_2 belongs to Cluster 24\n",
      "Embedding wmt14_translate_fr_en_1_0_0 belongs to Cluster 13\n",
      "Embedding quarel_testing_students belongs to Cluster 21\n",
      "Embedding wiki_hop_original_choose_best_object_affirmative_2 belongs to Cluster 14\n",
      "Embedding qasc_qa_with_separated_facts_4 belongs to Cluster 6\n",
      "Embedding duorc_SelfRC_movie_director belongs to Cluster 20\n",
      "Embedding wiki_qa_Topic_Prediction_Question_and_Answer_Pair belongs to Cluster 5\n",
      "Embedding cosmos_qa_1_0_0 belongs to Cluster 11\n",
      "Embedding cot_esnli_ii belongs to Cluster 10\n",
      "Embedding quail_no_prompt_id belongs to Cluster 8\n",
      "Embedding wmt16_translate_tr_en_1_0_0 belongs to Cluster 13\n",
      "Embedding wiki_qa_Decide_good_answer belongs to Cluster 5\n",
      "Embedding wiki_qa_Jeopardy_style belongs to Cluster 5\n",
      "Embedding adversarial_qa_dbert_based_on belongs to Cluster 19\n",
      "Embedding duorc_SelfRC_generate_question belongs to Cluster 16\n",
      "Embedding wiki_qa_Generate_Question_from_Topic belongs to Cluster 5\n",
      "Embedding wiki_hop_original_generate_subject_and_object belongs to Cluster 14\n",
      "Embedding adversarial_qa_dbidaf_based_on belongs to Cluster 19\n",
      "Embedding wiqa_what_is_the_missing_first_step belongs to Cluster 3\n",
      "Embedding quartz_read_passage_below_choose belongs to Cluster 6\n",
      "Embedding definite_pronoun_resolution_1_1_0 belongs to Cluster 5\n",
      "Embedding quail_no_prompt_text belongs to Cluster 8\n",
      "Embedding wiqa_effect_with_label_answer belongs to Cluster 21\n",
      "Embedding drop_2_0_0 belongs to Cluster 4\n",
      "Embedding race_middle_Select_the_best_answer_no_instructions_ belongs to Cluster 8\n",
      "Embedding glue_wnli_2_0_0 belongs to Cluster 5\n",
      "Embedding wiki_bio_comprehension belongs to Cluster 17\n",
      "Embedding glue_mrpc_2_0_0 belongs to Cluster 24\n",
      "Embedding cot_qasc belongs to Cluster 21\n",
      "Embedding adversarial_qa_dbert_question_context_answer belongs to Cluster 19\n",
      "Embedding quoref_Given_Context_Answer_Question belongs to Cluster 20\n",
      "Embedding coqa_1_0_0 belongs to Cluster 10\n",
      "Embedding quartz_paragraph_question_plain_concat belongs to Cluster 15\n",
      "Embedding adversarial_qa_dbidaf_tell_what_it_is belongs to Cluster 19\n",
      "Embedding ropes_prompt_mix belongs to Cluster 1\n",
      "Embedding social_i_qa_Generate_answer belongs to Cluster 11\n",
      "Embedding cot_strategyqa_ii belongs to Cluster 5\n",
      "Embedding quarel_logic_test belongs to Cluster 21\n",
      "Embedding duorc_ParaphraseRC_build_story_around_qa belongs to Cluster 22\n",
      "Embedding stream_aqua_ii belongs to Cluster 21\n",
      "Embedding multi_news_1_0_0 belongs to Cluster 17\n",
      "Embedding ropes_background_situation_middle belongs to Cluster 1\n",
      "Embedding sciq_Multiple_Choice_Question_First belongs to Cluster 6\n",
      "Embedding squad_v1_1_3_0_0 belongs to Cluster 4\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "clusters=defaultdict(list)\n",
    "# Print the cluster labels for each embedding\n",
    "for key, label in zip(module2embed.keys(), cluster_labels):\n",
    "    print(f\"Embedding {key} belongs to Cluster {label}\")\n",
    "    clusters[label].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c2o25_2e = ['glue_sst2_2_0_0', 'true_case', 'cot_esnli', 'trec_1_0_0', 'yelp_polarity_reviews_0_2_0', 'glue_cola_2_0_0', 'ag_news_subset_1_0_0', 'math_dataset_algebra__linear_1d_1_0_0', 'fix_punct', 'imdb_reviews_plain_text_1_0_0', 'word_segment', 'anli_r2_0_1_0', 'anli_r1_0_1_0']\n",
      "c21o25_2e = ['dream_read_the_following_conversation_and_answer_the_question', 'race_middle_Is_this_the_right_answer', 'race_high_Is_this_the_right_answer', 'quarel_do_not_use', 'dream_baseline', 'quarel_heres_a_story', 'quarel_choose_between', 'social_i_qa_Show_choices_and_generate_index', 'quarel_testing_students', 'wiqa_effect_with_label_answer', 'cot_qasc', 'quarel_logic_test', 'stream_aqua_ii']\n",
      "c8o25_2e = ['race_middle_Read_the_article_and_answer_the_question_no_option_', 'race_high_Select_the_best_answer', 'quail_description_context_question_answer_id', 'quail_context_question_description_text', 'race_high_Read_the_article_and_answer_the_question_no_option_', 'race_high_Select_the_best_answer_no_instructions_', 'quail_context_description_question_answer_id', 'race_high_Taking_a_test', 'race_middle_Select_the_best_answer', 'quail_context_question_description_answer_id', 'quail_description_context_question_answer_text', 'quail_context_question_answer_description_text', 'race_high_Select_the_best_answer_generate_span_', 'race_middle_Select_the_best_answer_generate_span_', 'quail_context_question_answer_description_id', 'quail_context_description_question_answer_text', 'quail_context_description_question_text', 'quail_context_question_description_answer_text', 'quail_description_context_question_text', 'race_middle_Taking_a_test', 'quail_no_prompt_id', 'quail_no_prompt_text', 'race_middle_Select_the_best_answer_no_instructions_']\n",
      "c23o25_2e = ['adversarial_qa_droberta_generate_question', 'dbpedia_14_pick_one_category_for_the_following_text', 'dbpedia_14_given_a_choice_of_categories_', 'adversarial_qa_dbidaf_generate_question', 'dbpedia_14_given_list_what_category_does_the_paragraph_belong_to', 'dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to', 'adversarial_qa_dbert_generate_question']\n",
      "c19o25_2e = ['adversarial_qa_dbidaf_question_context_answer', 'adversarial_qa_droberta_tell_what_it_is', 'adversarial_qa_droberta_based_on', 'adversarial_qa_dbert_answer_the_following_q', 'adversarial_qa_droberta_question_context_answer', 'adversarial_qa_dbidaf_answer_the_following_q', 'adversarial_qa_droberta_answer_the_following_q', 'adversarial_qa_dbert_tell_what_it_is', 'adversarial_qa_dbert_based_on', 'adversarial_qa_dbidaf_based_on', 'adversarial_qa_dbert_question_context_answer', 'adversarial_qa_dbidaf_tell_what_it_is']\n",
      "c9o25_2e = ['app_reviews_convert_to_star_rating', 'social_i_qa_Show_choices_and_generate_answer', 'app_reviews_categorize_rating_using_review', 'kilt_tasks_hotpotqa_final_exam', 'wiqa_does_the_supposed_perturbation_have_an_effect', 'cot_gsm8k_ii', 'super_glue_multirc_1_0_2', 'wiqa_which_of_the_following_is_the_supposed_perturbation', 'app_reviews_convert_to_rating', 'wiqa_effect_with_string_answer', 'kilt_tasks_hotpotqa_complex_question', 'wiki_qa_automatic_system', 'cot_creak_ii', 'cot_sensemaking_ii', 'social_i_qa_Check_if_a_random_answer_is_valid_or_not', 'social_i_qa_Generate_the_question_from_the_answer']\n",
      "c24o25_2e = ['super_glue_rte_1_0_2', 'super_glue_wic_1_0_2', 'anli_r3_0_1_0', 'paws_wiki_1_1_0', 'wiki_qa_Is_This_True_', 'glue_qqp_2_0_0', 'qasc_is_correct_1', 'glue_qnli_2_0_0', 'glue_mnli_2_0_0', 'qasc_is_correct_2', 'glue_mrpc_2_0_0']\n",
      "c3o25_2e = ['wiqa_what_might_be_the_first_step_of_the_process', 'wiqa_what_is_the_final_step_of_the_following_process', 'wiqa_what_might_be_the_last_step_of_the_process', 'wiqa_what_is_the_missing_first_step']\n",
      "c10o25_2e = ['stream_qed', 'huggingface_xsum', 'cot_gsm8k', 'gem_wiki_lingua_english_en_1_1_0', 'gigaword_1_2_0', 'aeslc_1_0_0', 'cot_esnli_ii', 'coqa_1_0_0']\n",
      "c6o25_2e = ['cos_e_v1_11_question_option_description_text', 'sciq_Direct_Question_Closed_Book_', 'qasc_qa_with_separated_facts_3', 'sciq_Multiple_Choice', 'cos_e_v1_11_question_description_option_text', 'sciq_Direct_Question', 'qasc_qa_with_separated_facts_2', 'cos_e_v1_11_question_option_description_id', 'qasc_qa_with_separated_facts_5', 'quartz_having_read_above_passage', 'cos_e_v1_11_question_description_option_id', 'qasc_qa_with_separated_facts_1', 'cos_e_v1_11_description_question_option_text', 'qasc_qa_with_combined_facts_1', 'cos_e_v1_11_description_question_option_id', 'sciq_Multiple_Choice_Closed_Book_', 'qasc_qa_with_separated_facts_4', 'quartz_read_passage_below_choose', 'sciq_Multiple_Choice_Question_First']\n",
      "c1o25_2e = ['ropes_background_new_situation_answer', 'ropes_prompt_bottom_no_hint', 'ropes_plain_background_situation', 'ropes_new_situation_background_answer', 'ropes_given_background_situation', 'ropes_prompt_bottom_hint_beginning', 'ropes_prompt_beginning', 'ropes_read_background_situation', 'ropes_plain_bottom_hint', 'ropes_plain_no_background', 'ropes_prompt_mix', 'ropes_background_situation_middle']\n",
      "c5o25_2e = ['wiki_qa_found_on_google', 'super_glue_cb_1_0_2', 'wiki_qa_Topic_Prediction_Answer_Only', 'wiki_qa_Direct_Answer_to_Question', 'super_glue_wsc_fixed_1_0_2', 'unified_qa_science_inst', 'cot_strategyqa', 'cot_ecqa_ii', 'wiki_qa_exercise', 'stream_qed_ii', 'wiki_qa_Topic_Prediction_Question_Only', 'super_glue_copa_1_0_2', 'wiki_qa_Topic_Prediction_Question_and_Answer_Pair', 'wiki_qa_Decide_good_answer', 'wiki_qa_Jeopardy_style', 'wiki_qa_Generate_Question_from_Topic', 'definite_pronoun_resolution_1_1_0', 'glue_wnli_2_0_0', 'cot_strategyqa_ii']\n",
      "c11o25_2e = ['cot_sensemaking', 'cot_creak', 'stream_aqua', 'snli_1_1_0', 'glue_stsb_2_0_0', 'social_i_qa_I_was_wondering', 'cosmos_qa_1_0_0', 'social_i_qa_Generate_answer']\n",
      "c15o25_2e = ['quartz_answer_question_based_on', 'quartz_given_the_fact_answer_the_q', 'quartz_answer_question_below', 'quartz_use_info_from_question_paragraph', 'quartz_use_info_from_paragraph_question', 'quartz_paragraph_question_plain_concat']\n",
      "c4o25_2e = ['super_glue_record_1_0_2', 'quoref_Guess_Title_For_Context', 'quac_1_0_0', 'squad_v2_0_3_0_0', 'wiki_bio_guess_person', 'drop_2_0_0', 'squad_v1_1_3_0_0']\n",
      "c20o25_2e = ['quoref_Context_Contains_Answer', 'quoref_Find_Answer', 'duorc_ParaphraseRC_movie_director', 'quoref_Found_Context_Online', 'quoref_Read_And_Extract_', 'quoref_What_Is_The_Answer', 'quoref_Answer_Test', 'quoref_Answer_Question_Given_Context', 'quoref_Guess_Answer', 'quoref_Answer_Friend_Question', 'duorc_SelfRC_movie_director', 'quoref_Given_Context_Answer_Question']\n",
      "c0o25_2e = ['cos_e_v1_11_rationale', 'cos_e_v1_11_generate_explanation_given_text', 'cos_e_v1_11_i_think', 'cos_e_v1_11_explain_why_human', 'cot_ecqa', 'cos_e_v1_11_aligned_with_common_sense']\n",
      "c7o25_2e = ['natural_questions_open_1_0_0', 'web_questions_whats_the_answer', 'web_questions_question_answer', 'kilt_tasks_hotpotqa_combining_facts', 'web_questions_short_general_knowledge_q', 'kilt_tasks_hotpotqa_straighforward_qa', 'web_questions_get_the_answer', 'web_questions_potential_correct_answer', 'trivia_qa_rc_1_1_0', 'kilt_tasks_hotpotqa_formulate']\n",
      "c16o25_2e = ['duorc_SelfRC_generate_question_by_answer', 'duorc_ParaphraseRC_answer_question', 'duorc_ParaphraseRC_title_generation', 'duorc_ParaphraseRC_decide_worth_it', 'duorc_ParaphraseRC_generate_question', 'duorc_SelfRC_question_answering', 'duorc_SelfRC_title_generation', 'duorc_ParaphraseRC_generate_question_by_answer', 'duorc_ParaphraseRC_extract_answer', 'duorc_SelfRC_answer_question', 'duorc_SelfRC_decide_worth_it', 'duorc_ParaphraseRC_question_answering', 'duorc_SelfRC_extract_answer', 'duorc_SelfRC_generate_question']\n",
      "c12o25_2e = ['lambada_1_0_0', 'dream_generate_last_utterance', 'cnn_dailymail_3_4_0', 'race_middle_Write_a_multi_choice_question_for_the_following_article', 'race_high_Write_a_multi_choice_question_for_the_following_article', 'dream_generate_first_utterance', 'dream_answer_to_dialogue', 'race_high_Write_a_multi_choice_question_options_given_', 'race_middle_Write_a_multi_choice_question_options_given_']\n",
      "c13o25_2e = ['wmt16_translate_ro_en_1_0_0', 'wmt16_translate_de_en_1_0_0', 'wmt16_translate_fi_en_1_0_0', 'para_crawl_enes', 'wmt14_translate_fr_en_1_0_0', 'wmt16_translate_tr_en_1_0_0']\n",
      "c18o25_2e = ['gem_dart_1_1_0', 'gem_common_gen_1_1_0', 'gem_web_nlg_en_1_1_0', 'app_reviews_generate_review', 'gem_e2e_nlg_1_1_0']\n",
      "c14o25_2e = ['wiki_hop_original_generate_object', 'wiki_hop_original_choose_best_object_affirmative_3', 'wiki_hop_original_choose_best_object_interrogative_1', 'wiki_hop_original_explain_relation', 'wiki_hop_original_choose_best_object_affirmative_1', 'wiki_hop_original_choose_best_object_interrogative_2', 'wiki_hop_original_generate_subject', 'wiki_hop_original_choose_best_object_affirmative_2', 'wiki_hop_original_generate_subject_and_object']\n",
      "c17o25_2e = ['wiki_bio_key_content', 'wiki_bio_what_content', 'wiki_bio_who', 'wiki_bio_comprehension', 'multi_news_1_0_0']\n",
      "c22o25_2e = ['duorc_SelfRC_build_story_around_qa', 'duorc_ParaphraseRC_build_story_around_qa']\n"
     ]
    }
   ],
   "source": [
    "for c, l in clusters.items():\n",
    "    # print(f\"Cluster {c} has {len(l)} elements\")\n",
    "    print(f\"c{c}o{K}_2e = {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!! DEBUG MODE\n",
      "Cluster 8 has 22 elements\n",
      "['glue_sst2_2_0_0', 'adversarial_qa_droberta_generate_question', 'stream_qed', 'super_glue_record_1_0_2', 'yelp_polarity_reviews_0_2_0', 'lambada_1_0_0', 'dream_generate_last_utterance', 'ag_news_subset_1_0_0', 'duorc_ParaphraseRC_title_generation', 'adversarial_qa_dbidaf_generate_question', 'quoref_Guess_Title_For_Context', 'fix_punct', 'imdb_reviews_plain_text_1_0_0', 'race_middle_Write_a_multi_choice_question_for_the_following_article', 'duorc_SelfRC_title_generation', 'anli_r2_0_1_0', 'race_high_Write_a_multi_choice_question_for_the_following_article', 'anli_r1_0_1_0', 'cot_ecqa', 'race_high_Write_a_multi_choice_question_options_given_', 'adversarial_qa_dbert_generate_question', 'race_middle_Write_a_multi_choice_question_options_given_']\n",
      "Cluster 3 has 32 elements\n",
      "['dream_read_the_following_conversation_and_answer_the_question', 'cos_e_v1_11_question_option_description_text', 'social_i_qa_Show_choices_and_generate_answer', 'sciq_Direct_Question_Closed_Book_', 'qasc_qa_with_separated_facts_3', 'sciq_Multiple_Choice', 'cos_e_v1_11_question_description_option_text', 'sciq_Direct_Question', 'qasc_qa_with_separated_facts_2', 'wiqa_which_of_the_following_is_the_supposed_perturbation', 'cos_e_v1_11_question_option_description_id', 'cot_ecqa_ii', 'wiqa_effect_with_string_answer', 'quarel_do_not_use', 'qasc_qa_with_separated_facts_5', 'dream_baseline', 'quartz_having_read_above_passage', 'cos_e_v1_11_question_description_option_id', 'qasc_qa_with_separated_facts_1', 'quarel_heres_a_story', 'qasc_qa_with_combined_facts_1', 'cos_e_v1_11_description_question_option_id', 'quarel_choose_between', 'social_i_qa_Show_choices_and_generate_index', 'sciq_Multiple_Choice_Closed_Book_', 'quartz_use_info_from_paragraph_question', 'quarel_testing_students', 'qasc_qa_with_separated_facts_4', 'quartz_read_passage_below_choose', 'wiqa_effect_with_label_answer', 'quarel_logic_test', 'sciq_Multiple_Choice_Question_First']\n",
      "Cluster 4 has 23 elements\n",
      "['race_middle_Read_the_article_and_answer_the_question_no_option_', 'race_high_Select_the_best_answer', 'quail_description_context_question_answer_id', 'quail_context_question_description_text', 'race_high_Read_the_article_and_answer_the_question_no_option_', 'race_high_Select_the_best_answer_no_instructions_', 'quail_context_description_question_answer_id', 'race_high_Taking_a_test', 'race_middle_Select_the_best_answer', 'quail_context_question_description_answer_id', 'quail_description_context_question_answer_text', 'quail_context_question_answer_description_text', 'race_high_Select_the_best_answer_generate_span_', 'race_middle_Select_the_best_answer_generate_span_', 'quail_context_question_answer_description_id', 'quail_context_description_question_answer_text', 'quail_context_description_question_text', 'quail_context_question_description_answer_text', 'quail_description_context_question_text', 'race_middle_Taking_a_test', 'quail_no_prompt_id', 'quail_no_prompt_text', 'race_middle_Select_the_best_answer_no_instructions_']\n",
      "Cluster 0 has 53 elements\n",
      "['adversarial_qa_dbidaf_question_context_answer', 'true_case', 'cot_sensemaking', 'trec_1_0_0', 'quartz_answer_question_based_on', 'cos_e_v1_11_rationale', 'natural_questions_open_1_0_0', 'web_questions_whats_the_answer', 'anli_r3_0_1_0', 'kilt_tasks_hotpotqa_final_exam', 'glue_cola_2_0_0', 'cos_e_v1_11_generate_explanation_given_text', 'adversarial_qa_droberta_tell_what_it_is', 'cot_creak', 'cot_gsm8k_ii', 'math_dataset_algebra__linear_1d_1_0_0', 'quartz_use_info_from_question_paragraph', 'web_questions_question_answer', 'dbpedia_14_pick_one_category_for_the_following_text', 'dbpedia_14_given_a_choice_of_categories_', 'kilt_tasks_hotpotqa_combining_facts', 'web_questions_short_general_knowledge_q', 'kilt_tasks_hotpotqa_straighforward_qa', 'cos_e_v1_11_i_think', 'dbpedia_14_given_list_what_category_does_the_paragraph_belong_to', 'adversarial_qa_droberta_based_on', 'web_questions_get_the_answer', 'adversarial_qa_dbert_answer_the_following_q', 'kilt_tasks_hotpotqa_complex_question', 'dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to', 'adversarial_qa_droberta_question_context_answer', 'cos_e_v1_11_explain_why_human', 'cot_creak_ii', 'cos_e_v1_11_description_question_option_text', 'web_questions_potential_correct_answer', 'trivia_qa_rc_1_1_0', 'stream_qed_ii', 'wiki_bio_guess_person', 'cos_e_v1_11_aligned_with_common_sense', 'adversarial_qa_dbidaf_answer_the_following_q', 'adversarial_qa_droberta_answer_the_following_q', 'cot_sensemaking_ii', 'adversarial_qa_dbert_tell_what_it_is', 'kilt_tasks_hotpotqa_formulate', 'social_i_qa_I_was_wondering', 'cosmos_qa_1_0_0', 'adversarial_qa_dbert_based_on', 'adversarial_qa_dbidaf_based_on', 'drop_2_0_0', 'adversarial_qa_dbert_question_context_answer', 'adversarial_qa_dbidaf_tell_what_it_is', 'social_i_qa_Generate_answer', 'squad_v1_1_3_0_0']\n",
      "Cluster 5 has 42 elements\n",
      "['app_reviews_convert_to_star_rating', 'super_glue_rte_1_0_2', 'wiki_qa_found_on_google', 'app_reviews_categorize_rating_using_review', 'super_glue_wic_1_0_2', 'race_middle_Is_this_the_right_answer', 'super_glue_cb_1_0_2', 'wiki_qa_Topic_Prediction_Answer_Only', 'paws_wiki_1_1_0', 'wiki_qa_Direct_Answer_to_Question', 'super_glue_wsc_fixed_1_0_2', 'wiqa_does_the_supposed_perturbation_have_an_effect', 'wiki_qa_Is_This_True_', 'unified_qa_science_inst', 'super_glue_multirc_1_0_2', 'snli_1_1_0', 'app_reviews_convert_to_rating', 'race_high_Is_this_the_right_answer', 'cot_strategyqa', 'glue_qqp_2_0_0', 'wiki_qa_exercise', 'wiki_qa_automatic_system', 'qasc_is_correct_1', 'squad_v2_0_3_0_0', 'wiki_qa_Topic_Prediction_Question_Only', 'glue_stsb_2_0_0', 'glue_qnli_2_0_0', 'glue_mnli_2_0_0', 'super_glue_copa_1_0_2', 'social_i_qa_Check_if_a_random_answer_is_valid_or_not', 'social_i_qa_Generate_the_question_from_the_answer', 'qasc_is_correct_2', 'wiki_qa_Topic_Prediction_Question_and_Answer_Pair', 'wiki_qa_Decide_good_answer', 'wiki_qa_Jeopardy_style', 'wiki_qa_Generate_Question_from_Topic', 'definite_pronoun_resolution_1_1_0', 'glue_wnli_2_0_0', 'glue_mrpc_2_0_0', 'cot_qasc', 'cot_strategyqa_ii', 'stream_aqua_ii']\n",
      "Cluster 1 has 24 elements\n",
      "['wiqa_what_might_be_the_first_step_of_the_process', 'huggingface_xsum', 'cot_esnli', 'cot_gsm8k', 'gem_dart_1_1_0', 'gem_common_gen_1_1_0', 'stream_aqua', 'cnn_dailymail_3_4_0', 'gem_wiki_lingua_english_en_1_1_0', 'gigaword_1_2_0', 'gem_web_nlg_en_1_1_0', 'word_segment', 'app_reviews_generate_review', 'wmt16_translate_de_en_1_0_0', 'aeslc_1_0_0', 'dream_generate_first_utterance', 'wmt16_translate_fi_en_1_0_0', 'dream_answer_to_dialogue', 'gem_e2e_nlg_1_1_0', 'para_crawl_enes', 'wmt14_translate_fr_en_1_0_0', 'cot_esnli_ii', 'wiqa_what_is_the_missing_first_step', 'coqa_1_0_0']\n",
      "Cluster 7 has 11 elements\n",
      "['wiqa_what_is_the_final_step_of_the_following_process', 'wmt16_translate_ro_en_1_0_0', 'wiqa_what_might_be_the_last_step_of_the_process', 'wiki_bio_key_content', 'duorc_SelfRC_build_story_around_qa', 'wiki_bio_what_content', 'wiki_bio_who', 'wmt16_translate_tr_en_1_0_0', 'wiki_bio_comprehension', 'duorc_ParaphraseRC_build_story_around_qa', 'multi_news_1_0_0']\n",
      "Cluster 9 has 15 elements\n",
      "['ropes_background_new_situation_answer', 'ropes_prompt_bottom_no_hint', 'ropes_plain_background_situation', 'quartz_given_the_fact_answer_the_q', 'quartz_answer_question_below', 'ropes_new_situation_background_answer', 'ropes_given_background_situation', 'ropes_prompt_bottom_hint_beginning', 'ropes_prompt_beginning', 'ropes_read_background_situation', 'ropes_plain_bottom_hint', 'ropes_plain_no_background', 'quartz_paragraph_question_plain_concat', 'ropes_prompt_mix', 'ropes_background_situation_middle']\n",
      "Cluster 2 has 25 elements\n",
      "['quoref_Context_Contains_Answer', 'duorc_SelfRC_generate_question_by_answer', 'quoref_Find_Answer', 'duorc_ParaphraseRC_movie_director', 'duorc_ParaphraseRC_answer_question', 'quoref_Found_Context_Online', 'quoref_Read_And_Extract_', 'duorc_ParaphraseRC_decide_worth_it', 'quoref_What_Is_The_Answer', 'duorc_ParaphraseRC_generate_question', 'quac_1_0_0', 'quoref_Answer_Test', 'duorc_SelfRC_question_answering', 'duorc_ParaphraseRC_generate_question_by_answer', 'duorc_ParaphraseRC_extract_answer', 'duorc_SelfRC_answer_question', 'duorc_SelfRC_decide_worth_it', 'duorc_ParaphraseRC_question_answering', 'quoref_Answer_Question_Given_Context', 'duorc_SelfRC_extract_answer', 'quoref_Guess_Answer', 'quoref_Answer_Friend_Question', 'duorc_SelfRC_movie_director', 'duorc_SelfRC_generate_question', 'quoref_Given_Context_Answer_Question']\n",
      "Cluster 6 has 9 elements\n",
      "['wiki_hop_original_generate_object', 'wiki_hop_original_choose_best_object_affirmative_3', 'wiki_hop_original_choose_best_object_interrogative_1', 'wiki_hop_original_explain_relation', 'wiki_hop_original_choose_best_object_affirmative_1', 'wiki_hop_original_choose_best_object_interrogative_2', 'wiki_hop_original_generate_subject', 'wiki_hop_original_choose_best_object_affirmative_2', 'wiki_hop_original_generate_subject_and_object']\n"
     ]
    }
   ],
   "source": [
    "for c, l in clusters.items():\n",
    "    print(f\"Cluster {c} has {len(l)} elements\")\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
